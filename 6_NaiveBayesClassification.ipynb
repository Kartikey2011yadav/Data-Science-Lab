{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23d82708-ed8a-4cf6-a71a-701a46f8352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn import preprocessing \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.linear_model import PoissonRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import re\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818d1753-1c8d-4565-be19-8ad92d128d07",
   "metadata": {},
   "source": [
    "# NAÏVE BAYES CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153c91bb-551e-4c7a-a48b-d05cd60ad60f",
   "metadata": {},
   "source": [
    "## 1:Demonstrate application of Naïve Bayes Using Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2331802-b538-456b-a780-105d4a840c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11a4cc1d-4e23-4693-be20-01f1d8113334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "no_comment = train_df[train_df['comment_text'].isnull()]\n",
    "no_toxic = train_df[train_df['toxic'].isnull()]\n",
    "no_severe_toxic = train_df[train_df['severe_toxic'].isnull()]\n",
    "no_obscene = train_df[train_df['obscene'].isnull()]\n",
    "no_threat = train_df[train_df['threat'].isnull()]\n",
    "no_insult = train_df[train_df['insult'].isnull()]\n",
    "no_identity_hate = train_df[train_df['identity_hate'].isnull()]\n",
    "\n",
    "print(len(no_comment),len(no_toxic), len(no_severe_toxic), len(no_obscene), len(no_threat), len(no_insult), len(no_identity_hate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcc957d5-9bc5-494c-b998-e1141327574a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_comment = test_df[test_df['comment_text'].isnull()]\n",
    "len(no_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32df81ab-3f6e-4336-8d62-7017efc97b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text\n",
    "\n",
    "# clean comment_text in train_df \n",
    "train_df['comment_text'] = train_df['comment_text'].map(lambda com : clean_text(com))\n",
    "\n",
    "# clean comment_text in test_df \n",
    "test_df['comment_text'] = test_df['comment_text'].map(lambda com : clean_text(com))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21c4e097-a8f5-4a68-9fb7-5007d86bc512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "train_X = train_df['comment_text']\n",
    "test_X = test_df['comment_text']\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000) \n",
    "train_vect = vectorizer.fit_transform(train_X)\n",
    "test_vect = vectorizer.transform(test_X)\n",
    "\n",
    "train_vect.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec2a019e-aa22-4625-891c-ebe4222dadc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic [(0, 144277), (1, 15294)]\n",
      "severe_toxic [(0, 157976), (1, 1595)]\n",
      "obscene [(0, 151122), (1, 8449)]\n",
      "threat [(0, 159093), (1, 478)]\n",
      "insult [(0, 151694), (1, 7877)]\n",
      "identity_hate [(0, 158166), (1, 1405)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print('toxic',sorted(Counter(train_df['toxic']).items()))\n",
    "print('severe_toxic',sorted(Counter(train_df['severe_toxic']).items()))\n",
    "print('obscene',sorted(Counter(train_df['obscene']).items()))\n",
    "print('threat',sorted(Counter(train_df['threat']).items()))\n",
    "print('insult',sorted(Counter(train_df['insult']).items()))\n",
    "print('identity_hate',sorted(Counter(train_df['identity_hate']).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c6cdb55-9ad3-4914-9dc6-1645a0694540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label : toxic\n",
      "0 => 144277\n",
      "1 => 144277\n",
      "label : severe_toxic\n",
      "0 => 157976\n",
      "1 => 157976\n",
      "label : obscene\n",
      "0 => 151122\n",
      "1 => 151122\n",
      "label : threat\n",
      "0 => 159093\n",
      "1 => 159093\n",
      "label : insult\n",
      "0 => 151694\n",
      "1 => 151694\n",
      "label : identity_hate\n",
      "0 => 158166\n",
      "1 => 158166\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "oversampled_data = {}\n",
    "\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "for label in labels:\n",
    "    y = train_df[label].values  \n",
    "\n",
    "    # SMOTE \n",
    "    X_resampled, y_resampled = smote.fit_resample(train_vect, y)\n",
    "\n",
    "    # oversampled\n",
    "    oversampled_data[label] = (X_resampled, y_resampled)\n",
    "\n",
    "    unique, counts = np.unique(y_resampled, return_counts=True)\n",
    "    class_counts = dict(zip(unique, counts))\n",
    "    print(f'label : {label}')\n",
    "    print('0 =>', class_counts[0])\n",
    "    print('1 =>', class_counts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb046efd-1deb-49fb-a06a-2bf2cc631148",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02e3d3dd-a7bd-4993-ae67-a8e96120b24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: toxic\n",
      "Test accuracy: 0.8838349708027933\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.89     28854\n",
      "           1       0.90      0.86      0.88     28857\n",
      "\n",
      "    accuracy                           0.88     57711\n",
      "   macro avg       0.88      0.88      0.88     57711\n",
      "weighted avg       0.88      0.88      0.88     57711\n",
      "\n",
      "Category: severe_toxic\n",
      "Test accuracy: 0.9599943029861847\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96     31656\n",
      "           1       0.95      0.97      0.96     31535\n",
      "\n",
      "    accuracy                           0.96     63191\n",
      "   macro avg       0.96      0.96      0.96     63191\n",
      "weighted avg       0.96      0.96      0.96     63191\n",
      "\n",
      "Category: obscene\n",
      "Test accuracy: 0.9058545219937468\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91     30250\n",
      "           1       0.92      0.89      0.90     30199\n",
      "\n",
      "    accuracy                           0.91     60449\n",
      "   macro avg       0.91      0.91      0.91     60449\n",
      "weighted avg       0.91      0.91      0.91     60449\n",
      "\n",
      "Category: threat\n",
      "Test accuracy: 0.971432163172947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97     31868\n",
      "           1       0.95      0.99      0.97     31770\n",
      "\n",
      "    accuracy                           0.97     63638\n",
      "   macro avg       0.97      0.97      0.97     63638\n",
      "weighted avg       0.97      0.97      0.97     63638\n",
      "\n",
      "Category: insult\n",
      "Test accuracy: 0.9019908368766274\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90     30427\n",
      "           1       0.91      0.89      0.90     30251\n",
      "\n",
      "    accuracy                           0.90     60678\n",
      "   macro avg       0.90      0.90      0.90     60678\n",
      "weighted avg       0.90      0.90      0.90     60678\n",
      "\n",
      "Category: identity_hate\n",
      "Test accuracy: 0.9319708536835949\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93     31550\n",
      "           1       0.92      0.94      0.93     31717\n",
      "\n",
      "    accuracy                           0.93     63267\n",
      "   macro avg       0.93      0.93      0.93     63267\n",
      "weighted avg       0.93      0.93      0.93     63267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "models = {}\n",
    "\n",
    "for label in labels:\n",
    "    X_train_label, X_test_label, y_train_label, y_test_label = train_test_split(oversampled_data[label][0],oversampled_data[label][1],test_size=0.2, random_state=42) \n",
    "    \n",
    "    nb_model = MultinomialNB()\n",
    "    nb_model.fit(X_train_label, y_train_label)\n",
    "    \n",
    "    y_pred_label = nb_model.predict(X_test_label)\n",
    "    accuracy = accuracy_score(y_test_label, y_pred_label)\n",
    "    report = classification_report(y_test_label, y_pred_label)\n",
    "    \n",
    "    print(f'Category: {label}')\n",
    "    print(f'Test accuracy: {accuracy}')\n",
    "    print(report)\n",
    "\n",
    "    models[label] = nb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7023a74-1b00-49db-93e1-7520a0aa3543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.997129</td>\n",
       "      <td>0.997129</td>\n",
       "      <td>0.997129</td>\n",
       "      <td>0.997129</td>\n",
       "      <td>0.997129</td>\n",
       "      <td>0.997129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.011009</td>\n",
       "      <td>0.011009</td>\n",
       "      <td>0.011009</td>\n",
       "      <td>0.011009</td>\n",
       "      <td>0.011009</td>\n",
       "      <td>0.011009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.156403</td>\n",
       "      <td>0.156403</td>\n",
       "      <td>0.156403</td>\n",
       "      <td>0.156403</td>\n",
       "      <td>0.156403</td>\n",
       "      <td>0.156403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.008143</td>\n",
       "      <td>0.008143</td>\n",
       "      <td>0.008143</td>\n",
       "      <td>0.008143</td>\n",
       "      <td>0.008143</td>\n",
       "      <td>0.008143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.188677</td>\n",
       "      <td>0.188677</td>\n",
       "      <td>0.188677</td>\n",
       "      <td>0.188677</td>\n",
       "      <td>0.188677</td>\n",
       "      <td>0.188677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.997129      0.997129  0.997129  0.997129  0.997129   \n",
       "1  0000247867823ef7  0.011009      0.011009  0.011009  0.011009  0.011009   \n",
       "2  00013b17ad220c46  0.156403      0.156403  0.156403  0.156403  0.156403   \n",
       "3  00017563c3f7919a  0.008143      0.008143  0.008143  0.008143  0.008143   \n",
       "4  00017695ad8997eb  0.188677      0.188677  0.188677  0.188677  0.188677   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.997129  \n",
       "1       0.011009  \n",
       "2       0.156403  \n",
       "3       0.008143  \n",
       "4       0.188677  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_nb = pd.DataFrame({'id': test_df['id']})\n",
    "for label in labels:\n",
    "    y_prob_label = nb_model.predict_proba(test_vect)[:, 1]\n",
    "    submission_nb[label] = y_prob_label\n",
    "\n",
    "submission_nb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17e7109a-2f10-4650-aecc-ac2c86a9db86",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_nb.to_csv('submission_nb.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
